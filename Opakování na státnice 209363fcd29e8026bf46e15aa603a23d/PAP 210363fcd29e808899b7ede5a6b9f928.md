# PAP

# Superscalar technique

## Superscalar Technique

CÃ­lem tÃ©to techniky je zrychlit bÄ›h procesoru a to pomocÃ­ nÄ›kolika pÅ™Ã­stupÅ¯:

- paralelizace zpracovÃ¡nÃ­ instrukcÃ­ - superskalÃ¡rnÃ­ technika
- vykonÃ¡vÃ¡nÃ­ out-of-order - dynamic pipelines
- zÅ™etÄ›zenÃ­ instrukcÃ­ - pipelining
- forwarding - pokud jsou data potÅ™ebnÃ¡ rovnou k dalÅ¡Ã­mu vÃ½poÄtu, nemusÃ­m je odesÃ­lat zpÄ›t do pamÄ›ti ale mohu je rovnou vyuÅ¾Ã­t pÅ™i vÃ½poÄtu

## Data flow v super skalÃ¡rnÃ­m procesoru

### Overview

**KlasickÃ½ procesor**

- **IF:** instruction fetch - naÄtenÃ­ instrukce do instrukÄnÃ­ pamÄ›ti
- **ID:** instruction decode - pÅ™eloÅ¾enÃ­ instrukce na signÃ¡ly pro ALU a ostatnÃ­ jednotky, naÄtenÃ­ dat do odpovÃ­dajÃ­cÃ­ch registrÅ¯
- **EX:** execute - provedenÃ­ operace vÃ½poÄtu (napÅ™. seÄtenÃ­ dvou ÄÃ­sel)
- **MEM:** memory access - `write`/ `load` do nebo z pamÄ›ti
- **WB:** write back - zapsÃ¡nÃ­ vypoÄtenÃ© hodnoty zpÄ›t do registrÅ¯

**SuperskalÃ¡rnÃ­ procesor**

- **Fetch**: instruction fetch - naÄtenÃ­ instrukce do instrukÄnÃ­ pamÄ›ti
- **Decode:** instruction decode - pÅ™eloÅ¾enÃ­ instrukce na signÃ¡ly
- **Dispatch:** pÅ™esklÃ¡dÃ¡nÃ­ instrukcÃ­ z programovÃ©ho poÅ™adÃ­ do poÅ™adÃ­, kterÃ© je vhodnÃ© pro vykonÃ¡vÃ¡nÃ­ na danÃ© architektuÅ™e (out-of-order)
- **Execute**: ProvedenÃ­ operace a vÃ½poÄtu
- **Complete**: DokonÄenÃ­ instrukce a zjiÅ¡tÄ›nÃ­, Å¾e instrukce byla dokonÄena a jejÃ­ vÃ½sledek je pÅ™ipraven
- **Retire**: TrvalÃ© potvrzenÃ­ vÃ½sledkÅ¯ instrukce, tedy zapsÃ¡nÃ­ do architektornickÃ©ho stavu procesorÅ¯ a uvolnÄ›nÃ­ zdroje

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image.png)

*Ne vÅ¡echny instrukce projdou pÅ™es vÅ¡echny fÃ¡ze. NapÅ™Ã­klad add nevyuÅ¾Ã­vÃ¡ MEM fÃ¡zi*.

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%201.png)

### Fetch

Pipeline mÃ¡ Å¡Ã­Å™ku $W$ (dÃ¡na poÄtem paralelnÃ­ch pipeline). V rÃ¡mci kaÅ¾dÃ©ho cyklu jsme provÃ©st fetch aÅ¾ $W$ instrukcÃ­. K zrychlenÃ­ se vyuÅ¾Ã­vÃ¡ **I-cache** *(Instruction Cache)* proto v nÃ­ musÃ­ bÃ½t dost mÃ­sta, aby do nÃ­ Å¡lo vloÅ¾it alespoÅˆ $W$ instrukcÃ­ v jeden Äas.

VÃ½kon zpomaluje, pokud nejsou instrukce zarovnanÃ© (tj. na nÄ›jakÃ¡ pÅ™esahuje Å™Ã¡dek). Å˜eÅ¡enÃ­ existujÃ­ dvÄ›:

- statickÃ© - zarovnÃ¡nÃ­ provede kompilÃ¡tor
- dynamickÃ© - Å™eÅ¡eno hardwarem za bÄ›hu CPU

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%202.png)

DynamickÃ© je moÅ¾nÃ© realizovat pomocÃ­ dvoucestenÃ© asociativnÃ­ I-cache s auto-reliagnement 

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%203.png)

***POPIS:** Pokud nÃ¡m instrukce zaÄÃ­nÃ¡ na zaÄÃ¡tku Å™Ã¡dku, je to jednoduchÃ© (viz ÄervenÃ½ rÃ¡meÄek). ProblÃ©m je, kdyÅ¾ ale zaÄÃ­nÃ¡ uprostÅ™ed (modrÃ½ rÃ¡meÄek). Pak bychom potÅ™ebovali provÃ©st naÄtenÃ­ na dvarkÃ¡t. K tomu ale mÅ¯Å¾eme vyuÅ¾Ã­t moÅ¾nosti, kterÃ© tato technika umoÅ¾Åˆuje a to zmÄ›nit poslednÃ­ dva bity. TÃ­m jsem schopni pÅ™ejÃ­t o jedno polÃ­Äko dolÅ¯ a naÄÃ­st tak poÅ¾adovanÃ© instrukce.
NÃ¡slednÄ› nesmÃ­me zapomenou na to, Å¾e je tÅ™eba zmÄ›nit poÅ™adÃ­, aby odpovÃ­dalo pÅ¯vodnÃ­mu.*

### Decode

RozdÃ­lnÃ¡ obtÃ­Å¾nost pro RISC a CISC instrukce, CISC majÃ­ promÄ›nlivou dÃ©llku.

FÃ¡ze nicmÃ©nÄ› musÃ­ provÃ©st nÃ¡sledujÃ­cÃ­ kroky:

- identifikovat individuÃ¡lnÃ­ instrukci
- rozeznat typ instrukce
- detekovat zÃ¡vislosti a mnoÅ¾inu instrukcÃ­, kterÃ© nemajÃ­ Å¾Ã¡dnou zÃ¡vislost, kterÃ¡ by je blokovala odeslat do dalÅ¡Ã­ fÃ¡ze (dispatch)

### Dispatch

CÃ­lem tÃ©to fÃ¡ze je primÃ¡rnÄ› roztÅ™Ã­dit instrukce k odpovÃ­dajÃ­cÃ­m jednotkÃ¡m na zpracovÃ¡nÃ­.

**Dispatch buffer** - uklÃ¡dÃ¡ dekÃ³dovanÃ© instrukce, kde poÅ™adÃ­ zÃ¡leÅ¾Ã­ na logice kÃ³du. NÃ¡slednÄ› jsou instrukce pÅ™eskupeny jinak, aby odpovÃ­dali vhodnosti pro architekturu (napÅ™. pokud budeme mÃ­t vÃ­ce ALU jednotek Äi jednotek, kterÃ© se starajÃ­ o pÅ™Ã­stup k pamÄ›ti, mÅ¯Å¾eme spustit 2 operace, kterÃ© na sobÄ› nezÃ¡visÃ­ paralelnÄ›).

Instrukce, kterÃ½m chybÃ­ data pro vykonÃ¡nÃ­ jsou uloÅ¾eny do rezervaÄnÃ­ch stanic. ExistujÃ­ tyto typy:

- Centralized - spotÅ™ebovÃ¡vÃ¡ vÃ­ce hardwarovÃ½ch prostÅ™edkÅ¯, ale je efektivnÄ›jÅ¡Ã­
- Distributed - mÃ©nÄ› HW resources
- Hybrid (clustered) - kombinuje obÄ› dvÄ› metody

![Centralized reservation station](PAP%20210363fcd29e808899b7ede5a6b9f928/image%204.png)

Centralized reservation station

![Distributed reservation station](PAP%20210363fcd29e808899b7ede5a6b9f928/image%205.png)

Distributed reservation station

### Execute

Je tvoÅ™ena vÃ­ce jednotkami a vÄ›tÅ¡Ã­ Å¡Ã­Å™kou pipeline. SouÄasnÃ½ trend je mÃ­t rozdÃ­lnÃ© pipeline, kterÃ© jsou specifickÃ© pro rÅ¯znÃ© operace.

DÃ¡le je otÃ¡zka, jak nejlÃ©pe nakombinovat pipeline, abyc fungovala optimÃ¡lnÄ›. ZÃ¡leÅ¾Ã­ na hardware a poÅ¾adavcÃ­ch na vÃ½poÄty, ale pravidlo znÃ­ 2:1:2 (2x ALU, 1x branch, 2x Load/Store)

### Complete

Instrukce je povaÅ¾ovanÃ¡ za *completed**,*** jakmile dokonÄÃ­ svÃ© vykonÃ¡vÃ¡nÃ­ a aktualizuje stav stroje. Jakmile opustÃ­ executing unit, je uloÅ¾ena do **reorder bufferu**, kde mÅ¯Å¾e Äekat i nÄ›jakou dobu neÅ¾ je retired. Je totiÅ¾ tÅ™eba zajistit, aby instrukce opouÅ¡tÄ›la procesor v programovÃ©m poÅ™adÃ­.

**Reorder buffer (Complete buffer)** - uklÃ¡dÃ¡ dokonÄenÃ© instrukce a seskupuje je do pÅ¯vodnÃ­ho programovÃ©ho poÅ™adÃ­. Je nutnÃ½ pro podporu preciznÃ­ch vyjÃ­mek.

### Retire

Instrukce je retired, jakmile opustÃ­ reorder / complete buffer a je aktualizovana v D-Cache (Data Chache).

## Tomasulo algorithm

Algoritmus poskytuje zajiÅ¡Å¥uje **register renaming techique**. Tato technika umoÅ¾Åˆuje abstraovat logickÃ© registry od fyzickÃ½ch. Tedy systÃ©m mÅ¯Å¾e efektivnÄ› pÅ™eplÃ¡novat a vyuÅ¾Ã­t registr, kterÃ½ je aktuÃ¡lnÄ› volnÃ½ a nenÃ­ nutnÃ© Äekat na specifikovanÃ½ register. To je dÅ¯leÅ¾itÃ© primÃ¡rnÄ› pro out-of-order vykonÃ¡vÃ¡nÃ­.

Algoritmus Å™eÅ¡Ã­ zÃ¡vislosti mezi jednotlivÃ½mi instrukcemi.

- ğŸ¦™ PÅ™Ã­klad
    
    PÅ™Ã­kladem mÅ¯Å¾e bÃ½t mÄ›jmÄ› procesor s 2x ALU.
    
    1. ALU umÃ­ sÄÃ­tat a odÄÃ­tat a doba pro obÄ› dvÄ› operace trvÃ¡ 2 cykly.
    2. ALU umÃ­ nÃ¡sobit a dÄ›lit, dÄ›lenÃ­ trvÃ¡ 12 cyklÅ¯ a nÃ¡sobenÃ­ 3 cykly.
    
    A mÄ›jme sekvenici instrukcÃ­
    
    ```
    R1 = R2 + R3
    R2 = R3 * R4
    R3 = R1 + R2
    ```
    
    A stavy registrÅ¯
    
    ```
    R1 = 12
    R2 = 2
    R3 = 5
    R4 = 1
    ```
    
    Algortimus vytvoÅ™Ã­ pouÅ¾Ã­vÃ¡ dva typy tabulek:
    
    Architectural Registers
    
    ![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%206.png)
    
    Reservation Station
    
    ![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%207.png)
    
    `tag` znaÄÃ­ na dokonÄenÃ­ jakÃ© instrukce z rezervaÄnÃ­ stanice se ÄekÃ¡
    

## PreciznÃ­ vyjÃ­mka

ProtoÅ¾e vykonÃ¡vÃ¡me out-of-order a i vÃ­ce instrukcÃ­ zÃ¡roveÅˆ, mÅ¯Å¾e dojÃ­t k vÃ­ce vyjÃ­mkÃ¡m bÄ›hem jednoho cyklu, kaÅ¾dÃ¡ ale natÃ¡vÃ¡ jindy v programovÃ©m poÅ™adÃ­.

KlasickÃ½ Tomasulo Algoritmus nepodporuje **preciznÃ­ vyjÃ­mku.**

- **Klasifikace exceptions/interrupts**
    - **Exception** - internÃ­
    - **Interrupt** - externÃ­
    
    **PÅ™Ã­kady:**
    
    - I/O Device Request (interrypt)
    - Breakpoint
    - ALU/FP exception
    - Page Fault
    - Undefined Opcode
    - Error in HW (parity, ECC, low voltage, â€¦)
    
    **Klasifikace**:
    
    - internÃ­ x externÃ­
    - hardware x software
    - synchronous x asynchronous
    - â€¦

Aby se jednalo o preciznÃ­ vyjÃ­mku, musÃ­ platit:

1. Procesor se exception vypoÅ™Ã¡dÃ¡ v programovÃ©m poÅ™adÃ­ (ne vykonÃ¡vanÃ©m poÅ™adÃ­)
2. Stav procesoru je konzistentnÃ­ pÅ™ed spuÅ¡tÄ›nÃ­m handleru vyjÃ­mky
    - tedy vÅ¡echny instrukce pÅ™ed spuÅ¡tÄ›nÃ­m vyjÃ­mky jsou ve stavu *completed* (pÅ™Ã­padnÄ› *retired*)
    - Å¾Ã¡dnÃ¡ instrukce po vyjÃ­mce nemÄ›nÃ­ stav procesoru nebo pamÄ›ti

**Commit stage** - fÃ¡ze, kdy jsme si jisti, Å¾e instrukce nemohou zpÅ¯sobit vyjÃ­mku. Po tomto stÃ¡diu mohou bÃ½t instrukce *retired* pokud vÅ¡echny instrukce pÅ™edem (v programovÃ©m poÅ™adÃ­) jsou *commited* a *completed*.

## Data speculation

- zkusÃ­m udÄ›lat vypoÄet s daty, o kterÃ½ch tuÅ¡Ã­m, Å¾e mi zachvilku pÅ™ijdou

Aplikace

- for cyklus - Ätu z pamÄ›ti
- scanf - Ätu sekvenÄnÄ› data

## Branch predictor

ObecnÄ› se sklÃ¡dÃ¡ ze dvou komponent:

- branch target speculation - kde je dalÅ¡Ã­ instrukce
- branch condition speculation - mÃ¡m skoÄit nebo ne

### Condition speculation - skÃ¡Äeme?

NejvÃ­c base je **Smithâ€™s 2 bit predictor**, kterÃ½ vyuÅ¾Ã­vÃ¡ lokÃ¡lnÃ­ historii.

**Pattern History Table**

SklÃ¡dÃ¡ se z nÄ›kolika komponent:

- Branch Address - adresa instrukce
- Branch History Table - pro adresu instrukce uklÃ¡dÃ¡ historii - nenÃ­ nic jinÃ©ho, neÅ¾ shiftovanÃ¡ hodnota
- Pattern History Table - adresa se sklÃ¡dÃ¡ z ÄÃ¡sti Branch Address a hodnoty v Branch History Table, kterÃ¡ odpovÃ­dÃ¡ danÃ©mu patternu

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%208.png)

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%209.png)

GlobÃ¡lnÃ­ historie - vyuÅ¾Ã­vÃ¡ pouze jeden history register

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2010.png)

LokÃ¡lnÃ­ historie - vyuÅ¾Ã­vÃ¡ register pro kaÅ¾dou adresu (dle poslednÃ­ch 3 bitÅ¯)

**ZlepÅ¡enÃ­:**

- vyuÅ¾itÃ­ hashovacÃ­ funkce - rovnomÄ›rnÄ›jÅ¡Ã­ zaplnÄ›nÃ­ pattern table
- vÃ­ce ÃºrovnÃ­ pattern table

- kombinaci lokÃ¡lnÃ­ a globÃ¡lnÃ­ historie (alloyed predictor)

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2011.png)

**JinÃ© neÅ¾ pattern history predictory**

- gskewed predictor - vyuÅ¾Ã­vÃ¡ majoritu ze tÅ™Ã­
- agree predictor - rozhoduje na zÃ¡kladÄ› odchylky jestli skÃ¡kat nebo ne
- **YAGS** predictor - 2 prediktory, jeden Å™Ã­kÃ¡ zdali skÃ¡kat, druhÃ½ zdali neskÃ¡kat
- â€¦

### Branch Target Predictor - kam skÃ¡Äeme?

VyuÅ¾Ã­vÃ¡ 2 cache - kde pÃ¡ruje adresu instrukce a cÃ­l instrukce. Je to ale komplikovanÃ© u objektovÃ©ho programovÃ¡nÃ­, proto vyuÅ¾Ã­vÃ¡me *Virtual Program Counter*, kterÃ½ se dokÃ¡Å¾e nauÄit pattern skokÅ¯.

S **Instruction Prefetching** nÃ¡m pomÃ¡hajÃ­ 2 mechanismy:

- **Collapsing buffer** - pamatuje si pÅ™eskoÄenÃ­ instrukcÃ­

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2012.png)

- **Trace cache -** *odkladiÅ¡tÄ› pro vykonanÃ© instrukce*, vykonanÃ© instrukce odklÃ¡dÃ¡me do alokovanÃ©ho prostoru a nÃ¡slednÄ› je dekÃ³dujeem z trace cache

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2013.png)

## Speeding up Load-Store instructions

**Load bypassing** pokud v danÃ© operaci neuklÃ¡dÃ¡m data na stejnou pamÄ›Å¥ z kterÃ© budu ÄÃ­st, mohu je rovnou pÅ™ejÃ­t k dalÅ¡Ã­mu kroku a naÄÃ­st je.

**Load forwarding** pokud budou naÄÃ­tanÃ¡ data rovnou pouÅ¾it, neuklÃ¡dÃ¡m je do cache, ale rovnou posÃ­lÃ¡m pÅ™es common data bus do load jednotky.

**Out-of-order loading** - pokud jsou data naÄÃ­tnÃ¡ spekulativnÄ›, musÃ­m je oznaÄit. Pokud dojde ke kolizi, musÃ­m zopakovat naÄÃ­tÃ¡nÃ­ a invalidovat vÅ¡echny instrukce, kterÃ© vyuÅ¾Ã­vajÃ­ inkonzistenÃ­ data.

**Non-blocking cache** funguje dÃ­ky dvÄ›ma zÃ¡kladnÃ­m pÅ™Ã­stupÅ¯m:

- **hit-under-miss**: pokud se nÃ¡m jedna instrukce nenaÄte, protoÅ¾e nenÃ­ v cache, zkusÃ­m ji pÅ™eskoÄit a naÄÃ­st nÃ¡sledujÃ­cÃ­ a pokud tam je, pustÃ­m se do jejÃ­ho vykonÃ¡vÃ¡nÃ­
- **miss-under-miss (hit-under-multiple-misses)**: odloÅ¾Ã­me $n$ operacÃ­, kterÃ© pÅ™istupujÃ­ do pamÄ›ti

**Prefetching data** - odhadujeme, jakÃ¡ data budou potÅ™eba a ty pÅ™ed naÄteme. V modernÃ­ch instrukÄnÃ­ch sadÃ¡ch pro tuto operaci existuje speciÃ¡lnÃ­ instrukce.

- **Write trough** - zÃ¡pisy jdou do cache a zÃ¡roveÅˆ do write bufferu

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2014.png)

- **Write back** - nastavujeme jenom do cache a aÅ¾ pokud potÅ™ebujeme data vymÄ›nit, zapÃ­Å¡eme je do write bufferu, zde musÃ­me vyuÅ¾Ã­t **dirty bit**

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2015.png)

**Victim cache** funguje tak, Å¾e vyhozenÃ¡ data si nachvilku jeÅ¡tÄ› nechÃ¡me stranou, protoÅ¾e by se nÃ¡m mohli hodit. (obÄ›ti nechÃ¡m chvilku v mÃ¡rnici neÅ¾ je spÃ¡lÃ­m)

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2016.png)

**Assist cache** prvnÄ› natÃ¡hneme data do tÃ©to pamÄ›ti a aÅ¾ pokud je vyuÅ¾ijeme znovu, dÃ¡me je do hlavnÃ­ cache. (je se tÅ™eba osvÄ›dÄit)

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2017.png)

**Transaltion lookaside buffer (TLB)** nÄ›kdy oznaÄovÃ¡n jako ***Translation Cache:*** operace pÅ™ekladu virtuÃ¡lnÃ­ pamÄ›ti na fyzickou je drahÃ¡, mÅ¯Å¾eme mÃ­t vÃ­ce ÃºrovÅˆovÃ© strÃ¡nkovÃ¡nÃ­. Proto vloÅ¾Ã­me do bufferu a nemusÃ­me provÃ¡dÄ›t pÅ™eklad znovu.

# Coherency & consistency on a system with shared bus

**Coherency** - vÅ¡echny procesory, kterÃ© se koukajÃ­ na stejnÃ© mÃ­sto v pamÄ›ti, musejÃ­ vidÄ›t stejnou vÄ›c.

ExistujÃ­ 2 zÃ¡kladnÃ­ metody, jak dosÃ¡hnout coherence:

- **snooping** - odposlouchÃ¡vÃ¡nÃ­ toho, co se dÄ›je na sbÄ›rnÃ­ci a zachovÃ¡vat se podle toho (MESI, MSI, MEI, MOESI, MESIF)
    - **write-update** - pokud se nÄ›co zmÄ›nÃ­, zmÄ›nÃ­m to ve vÅ¡ech cache
    - **write-invalid** - kdyÅ¾ pÅ™etahujeme nÄ›co k sobÄ›, zajistÃ­me, Å¾e to nikdo jinÃ½ nemÃ¡
- **directory-based** - CPU se ptÃ¡ skrze nÄ›jakÃ½ adresÃ¡Å™, zdali nÄ›kdo danou pamÄ›Å¥ nevyuÅ¾Ã­vÃ¡

**Consistency** - poÅ™adÃ­ operacÃ­ bude na vÅ¡ech procesorech vidÄ›no stejnÄ›.

ExistujÃ­ 2 Å™eÅ¡enÃ­

- vypnutÃ­ spekulacÃ­ - to ale nechceme
- izolovÃ¡nÃ­ procesÅ¯ na promÄ›nnÃ½ch, kterÃ© se pÅ™ekrÃ½vajÃ­ (tj. pokud chci provÃ©st zmÄ›nu ze stavu $M$ mÅ¯Å¾eme spekulovat, dokud se neobjevÃ­ akce Å™eÅ¡Ã­cÃ­ koherency, pak musÃ­m vÅ¡echny spekulace zlikvidovat)

## MESI

PostavenÃ½ na write-back, tedy zapisuje do pamÄ›ti aÅ¾ kdyÅ¾ data opouÅ¡tÃ­ cache. PotÅ™ebuje dirty bit.

KaÅ¾dÃ¡ cache line mÅ¯Å¾e bÃ½t ve 4 stavech:

- **Modified (M)** - ekvivalent pro dirty stav, data jsou modifikovÃ¡na
- **Exclusive (E)** - prvnÃ­, kdo data naÄetl a vÃ­me, Å¾e je jinÃ¡ cache line nemÃ¡, data mÅ¯Å¾eme opakovanÄ› ÄÃ­st a nemusÃ­me se nikoho ptÃ¡t, mÅ¯Å¾eme pÅ™ejÃ­t do stavu `modified`
- **Shared (S)** - data Äte vÃ­ce CPU, pokud chceme pÅ™ejÃ­t do stavu `modified`***,*** musÃ­me o tom informaovat vÅ¡echny, kteÅ™Ã­ jsou ve stavu `shared`
- **Invalid (I)** - cache line nenÃ­ pouÅ¾Ã­vanÃ¡

![LokÃ¡lnÃ­ procesor](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2018.png)

LokÃ¡lnÃ­ procesor

![OdposlouchÃ¡vajÃ­cÃ­ procesor](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2019.png)

OdposlouchÃ¡vajÃ­cÃ­ procesor

### MOESI

NavÃ­c pÅ™idÃ¡vÃ¡ stav:

- **Owened (O)** - ten umoÅ¾Åˆuje jednÃ© cache bÃ½t vlatnÃ­kem a mÃ­t prÃ¡v pro upravovÃ¡nÃ­ cache. OstatnÃ­ danou cache mohou pouze ÄÃ­st. OWNER musÃ­ broadcastovat novÃ½ stav, pokud hodnotu zmÄ›nÃ­.

## Directory

JinÃ½ pÅ™Ã­stup, je vhodnÃ½ pro pÅ™ipojenÃ­ velikÃ©ho mnoÅ¾stvÃ­ CPU, protoÅ¾e nezpÅ¯sobÃ­ to, Å¾e by doÅ¡lo k zahlcenÃ­ busu. Proto je rozdÄ›lÃ­me do menÅ¡Ã­ch skupin a kaÅ¾dÃ¡ skupina mÃ¡ svoje **directory**, kterÃ¡ definuje, jakÃ¡ data jsou pouÅ¾Ã­vanÃ¡ a jakÃ½ procesor je vyuÅ¾Ã­vÃ¡.

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2020.png)

Existuje centrÃ¡lnÃ­ mÃ­sto v pamÄ›ti, kterÃ¡ nÃ¡m uklÃ¡dÃ¡ veÅ¡kerÃ© informace a zde mÅ¯Å¾em zjistit, jakÃ½ node pouÅ¾Ã­vÃ¡ jakÃ¡ data.

MÅ¯Å¾e bÃ½t ve stavu jako MOESI.

MÅ¯Å¾e bÃ½t buÄto:

- Flat - kaÅ¾dÃ½ node mÃ¡ svoji pamÄ›Å¥
    - memory - pamatuji si vÅ¡echno
    - cached - linked list, pamatuji si jenom prvnÃ­
- Hierarchical
- Centralized - jedna spoleÄnÃ¡

# Rules for execution synchronization and data exchange

- [ ]  Rules for execution synchronization and data exchange in multiprocessor systems, mutex implementation, relation to consistency models and mechanism to achieve expected algorithms behavior on systems with relaxed consistency models (PRAM, PSO, TSO, PC, barrier instructions).

**SekvenÄnÃ­ konzistence** - relaxace, relaxuje pouze logickÃ© hodiny, tj. Å¾e se nemusejÃ­ stÃ¡t ve stejnÃ½ moment ale ve stejnÃ©m poÅ™adÃ­.

# SMP and NUMA networks

- [ ]  SMP and NUMA nodes interconnections networks, conflicts and rearrangeable networks BeneÅ¡ network.

# Parallel computations (OpenMP and MPI)

- [ ]  Parallel computations on multiprocessor systems, OpenMP on NUMA and MPI on distributed memory systems, their combinations.