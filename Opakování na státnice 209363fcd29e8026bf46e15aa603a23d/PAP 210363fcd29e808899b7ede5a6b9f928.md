# PAP

# Superscalar technique

## Superscalar Technique

Cílem této techniky je zrychlit běh procesoru a to pomocí několika přístupů:

- paralelizace zpracování instrukcí - superskalární technika
- vykonávání out-of-order - dynamic pipelines
- zřetězení instrukcí - pipelining
- forwarding - pokud jsou data potřebná rovnou k dalšímu výpočtu, nemusím je odesílat zpět do paměti ale mohu je rovnou využít při výpočtu

## Data flow v super skalárním procesoru

### Overview

**Klasický procesor**

- **IF:** instruction fetch - načtení instrukce do instrukční paměti
- **ID:** instruction decode - přeložení instrukce na signály pro ALU a ostatní jednotky, načtení dat do odpovídajících registrů
- **EX:** execute - provedení operace výpočtu (např. sečtení dvou čísel)
- **MEM:** memory access - `write`/ `load` do nebo z paměti
- **WB:** write back - zapsání vypočtené hodnoty zpět do registrů

**Superskalární procesor**

- **Fetch**: instruction fetch - načtení instrukce do instrukční paměti
- **Decode:** instruction decode - přeložení instrukce na signály
- **Dispatch:** přeskládání instrukcí z programového pořadí do pořadí, které je vhodné pro vykonávání na dané architektuře (out-of-order)
- **Execute**: Provedení operace a výpočtu
- **Complete**: Dokončení instrukce a zjištění, že instrukce byla dokončena a její výsledek je připraven
- **Retire**: Trvalé potvrzení výsledků instrukce, tedy zapsání do architektornického stavu procesorů a uvolnění zdroje

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image.png)

*Ne všechny instrukce projdou přes všechny fáze. Například add nevyužívá MEM fázi*.

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%201.png)

### Fetch

Pipeline má šířku $W$ (dána počtem paralelních pipeline). V rámci každého cyklu jsme provést fetch až $W$ instrukcí. K zrychlení se využívá **I-cache** *(Instruction Cache)* proto v ní musí být dost místa, aby do ní šlo vložit alespoň $W$ instrukcí v jeden čas.

Výkon zpomaluje, pokud nejsou instrukce zarovnané (tj. na nějaká přesahuje řádek). Řešení existují dvě:

- statické - zarovnání provede kompilátor
- dynamické - řešeno hardwarem za běhu CPU

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%202.png)

Dynamické je možné realizovat pomocí dvoucestené asociativní I-cache s auto-reliagnement 

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%203.png)

***POPIS:** Pokud nám instrukce začíná na začátku řádku, je to jednoduché (viz červený rámeček). Problém je, když ale začíná uprostřed (modrý rámeček). Pak bychom potřebovali provést načtení na dvarkát. K tomu ale můžeme využít možnosti, které tato technika umožňuje a to změnit poslední dva bity. Tím jsem schopni přejít o jedno políčko dolů a načíst tak požadované instrukce.
Následně nesmíme zapomenou na to, že je třeba změnit pořadí, aby odpovídalo původnímu.*

### Decode

Rozdílná obtížnost pro RISC a CISC instrukce, CISC mají proměnlivou déllku.

Fáze nicméně musí provést následující kroky:

- identifikovat individuální instrukci
- rozeznat typ instrukce
- detekovat závislosti a množinu instrukcí, které nemají žádnou závislost, která by je blokovala odeslat do další fáze (dispatch)

### Dispatch

Cílem této fáze je primárně roztřídit instrukce k odpovídajícím jednotkám na zpracování.

**Dispatch buffer** - ukládá dekódované instrukce, kde pořadí záleží na logice kódu. Následně jsou instrukce přeskupeny jinak, aby odpovídali vhodnosti pro architekturu (např. pokud budeme mít více ALU jednotek či jednotek, které se starají o přístup k paměti, můžeme spustit 2 operace, které na sobě nezávisí paralelně).

Instrukce, kterým chybí data pro vykonání jsou uloženy do rezervačních stanic. Existují tyto typy:

- Centralized - spotřebovává více hardwarových prostředků, ale je efektivnější
- Distributed - méně HW resources
- Hybrid (clustered) - kombinuje obě dvě metody

![Centralized reservation station](PAP%20210363fcd29e808899b7ede5a6b9f928/image%204.png)

Centralized reservation station

![Distributed reservation station](PAP%20210363fcd29e808899b7ede5a6b9f928/image%205.png)

Distributed reservation station

### Execute

Je tvořena více jednotkami a větší šířkou pipeline. Současný trend je mít rozdílné pipeline, které jsou specifické pro různé operace.

Dále je otázka, jak nejlépe nakombinovat pipeline, abyc fungovala optimálně. Záleží na hardware a požadavcích na výpočty, ale pravidlo zní 2:1:2 (2x ALU, 1x branch, 2x Load/Store)

### Complete

Instrukce je považovaná za *completed**,*** jakmile dokončí své vykonávání a aktualizuje stav stroje. Jakmile opustí executing unit, je uložena do **reorder bufferu**, kde může čekat i nějakou dobu než je retired. Je totiž třeba zajistit, aby instrukce opouštěla procesor v programovém pořadí.

**Reorder buffer (Complete buffer)** - ukládá dokončené instrukce a seskupuje je do původního programového pořadí. Je nutný pro podporu precizních vyjímek.

### Retire

Instrukce je retired, jakmile opustí reorder / complete buffer a je aktualizovana v D-Cache (Data Chache).

## Tomasulo algorithm

Algoritmus poskytuje zajišťuje **register renaming techique**. Tato technika umožňuje abstraovat logické registry od fyzických. Tedy systém může efektivně přeplánovat a využít registr, který je aktuálně volný a není nutné čekat na specifikovaný register. To je důležité primárně pro out-of-order vykonávání.

Algoritmus řeší závislosti mezi jednotlivými instrukcemi.

- 🦙 Příklad
    
    Příkladem může být mějmě procesor s 2x ALU.
    
    1. ALU umí sčítat a odčítat a doba pro obě dvě operace trvá 2 cykly.
    2. ALU umí násobit a dělit, dělení trvá 12 cyklů a násobení 3 cykly.
    
    A mějme sekvenici instrukcí
    
    ```
    R1 = R2 + R3
    R2 = R3 * R4
    R3 = R1 + R2
    ```
    
    A stavy registrů
    
    ```
    R1 = 12
    R2 = 2
    R3 = 5
    R4 = 1
    ```
    
    Algortimus vytvoří používá dva typy tabulek:
    
    Architectural Registers
    
    ![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%206.png)
    
    Reservation Station
    
    ![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%207.png)
    
    `tag` značí na dokončení jaké instrukce z rezervační stanice se čeká
    

## Precizní vyjímka

Protože vykonáváme out-of-order a i více instrukcí zároveň, může dojít k více vyjímkám během jednoho cyklu, každá ale natává jindy v programovém pořadí.

Klasický Tomasulo Algoritmus nepodporuje **precizní vyjímku.**

- **Klasifikace exceptions/interrupts**
    - **Exception** - interní
    - **Interrupt** - externí
    
    **Příkady:**
    
    - I/O Device Request (interrypt)
    - Breakpoint
    - ALU/FP exception
    - Page Fault
    - Undefined Opcode
    - Error in HW (parity, ECC, low voltage, …)
    
    **Klasifikace**:
    
    - interní x externí
    - hardware x software
    - synchronous x asynchronous
    - …

Aby se jednalo o precizní vyjímku, musí platit:

1. Procesor se exception vypořádá v programovém pořadí (ne vykonávaném pořadí)
2. Stav procesoru je konzistentní před spuštěním handleru vyjímky
    - tedy všechny instrukce před spuštěním vyjímky jsou ve stavu *completed* (případně *retired*)
    - žádná instrukce po vyjímce nemění stav procesoru nebo paměti

**Commit stage** - fáze, kdy jsme si jisti, že instrukce nemohou způsobit vyjímku. Po tomto stádiu mohou být instrukce *retired* pokud všechny instrukce předem (v programovém pořadí) jsou *commited* a *completed*.

## Data speculation

- zkusím udělat vypočet s daty, o kterých tuším, že mi zachvilku přijdou

Aplikace

- for cyklus - čtu z paměti
- scanf - čtu sekvenčně data

## Branch predictor

Obecně se skládá ze dvou komponent:

- branch target speculation - kde je další instrukce
- branch condition speculation - mám skočit nebo ne

### Condition speculation - skáčeme?

Nejvíc base je **Smith’s 2 bit predictor**, který využívá lokální historii.

**Pattern History Table**

Skládá se z několika komponent:

- Branch Address - adresa instrukce
- Branch History Table - pro adresu instrukce ukládá historii - není nic jiného, než shiftovaná hodnota
- Pattern History Table - adresa se skládá z části Branch Address a hodnoty v Branch History Table, která odpovídá danému patternu

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%208.png)

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%209.png)

Globální historie - využívá pouze jeden history register

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2010.png)

Lokální historie - využívá register pro každou adresu (dle posledních 3 bitů)

**Zlepšení:**

- využití hashovací funkce - rovnoměrnější zaplnění pattern table
- více úrovní pattern table

- kombinaci lokální a globální historie (alloyed predictor)

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2011.png)

**Jiné než pattern history predictory**

- gskewed predictor - využívá majoritu ze tří
- agree predictor - rozhoduje na základě odchylky jestli skákat nebo ne
- **YAGS** predictor - 2 prediktory, jeden říká zdali skákat, druhý zdali neskákat
- …

### Branch Target Predictor - kam skáčeme?

Využívá 2 cache - kde páruje adresu instrukce a cíl instrukce. Je to ale komplikované u objektového programování, proto využíváme *Virtual Program Counter*, který se dokáže naučit pattern skoků.

S **Instruction Prefetching** nám pomáhají 2 mechanismy:

- **Collapsing buffer** - pamatuje si přeskočení instrukcí

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2012.png)

- **Trace cache -** *odkladiště pro vykonané instrukce*, vykonané instrukce odkládáme do alokovaného prostoru a následně je dekódujeem z trace cache

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2013.png)

## Speeding up Load-Store instructions

**Load bypassing** pokud v dané operaci neukládám data na stejnou paměť z které budu číst, mohu je rovnou přejít k dalšímu kroku a načíst je.

**Load forwarding** pokud budou načítaná data rovnou použit, neukládám je do cache, ale rovnou posílám přes common data bus do load jednotky.

**Out-of-order loading** - pokud jsou data načítná spekulativně, musím je označit. Pokud dojde ke kolizi, musím zopakovat načítání a invalidovat všechny instrukce, které využívají inkonzistení data.

**Non-blocking cache** funguje díky dvěma základním přístupům:

- **hit-under-miss**: pokud se nám jedna instrukce nenačte, protože není v cache, zkusím ji přeskočit a načíst následující a pokud tam je, pustím se do jejího vykonávání
- **miss-under-miss (hit-under-multiple-misses)**: odložíme $n$ operací, které přistupují do paměti

**Prefetching data** - odhadujeme, jaká data budou potřeba a ty před načteme. V moderních instrukčních sadách pro tuto operaci existuje speciální instrukce.

- **Write trough** - zápisy jdou do cache a zároveň do write bufferu

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2014.png)

- **Write back** - nastavujeme jenom do cache a až pokud potřebujeme data vyměnit, zapíšeme je do write bufferu, zde musíme využít **dirty bit**

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2015.png)

**Victim cache** funguje tak, že vyhozená data si nachvilku ještě necháme stranou, protože by se nám mohli hodit. (oběti nechám chvilku v márnici než je spálím)

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2016.png)

**Assist cache** prvně natáhneme data do této paměti a až pokud je využijeme znovu, dáme je do hlavní cache. (je se třeba osvědčit)

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2017.png)

**Transaltion lookaside buffer (TLB)** někdy označován jako ***Translation Cache:*** operace překladu virtuální paměti na fyzickou je drahá, můžeme mít více úrovňové stránkování. Proto vložíme do bufferu a nemusíme provádět překlad znovu.

# Coherency & consistency on a system with shared bus

**Coherency** - všechny procesory, které se koukají na stejné místo v paměti, musejí vidět stejnou věc.

Existují 2 základní metody, jak dosáhnout coherence:

- **snooping** - odposlouchávání toho, co se děje na sběrníci a zachovávat se podle toho (MESI, MSI, MEI, MOESI, MESIF)
    - **write-update** - pokud se něco změní, změním to ve všech cache
    - **write-invalid** - když přetahujeme něco k sobě, zajistíme, že to nikdo jiný nemá
- **directory-based** - CPU se ptá skrze nějaký adresář, zdali někdo danou paměť nevyužívá

**Consistency** - pořadí operací bude na všech procesorech viděno stejně.

Existují 2 řešení

- vypnutí spekulací - to ale nechceme
- izolování procesů na proměnných, které se překrývají (tj. pokud chci provést změnu ze stavu $M$ můžeme spekulovat, dokud se neobjeví akce řešící koherency, pak musím všechny spekulace zlikvidovat)

## MESI

Postavený na write-back, tedy zapisuje do paměti až když data opouští cache. Potřebuje dirty bit.

Každá cache line může být ve 4 stavech:

- **Modified (M)** - ekvivalent pro dirty stav, data jsou modifikována
- **Exclusive (E)** - první, kdo data načetl a víme, že je jiná cache line nemá, data můžeme opakovaně číst a nemusíme se nikoho ptát, můžeme přejít do stavu `modified`
- **Shared (S)** - data čte více CPU, pokud chceme přejít do stavu `modified`***,*** musíme o tom informaovat všechny, kteří jsou ve stavu `shared`
- **Invalid (I)** - cache line není používaná

![Lokální procesor](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2018.png)

Lokální procesor

![Odposlouchávající procesor](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2019.png)

Odposlouchávající procesor

### MOESI

Navíc přidává stav:

- **Owened (O)** - ten umožňuje jedné cache být vlatníkem a mít práv pro upravování cache. Ostatní danou cache mohou pouze číst. OWNER musí broadcastovat nový stav, pokud hodnotu změní.

## Directory

Jiný přístup, je vhodný pro připojení velikého množství CPU, protože nezpůsobí to, že by došlo k zahlcení busu. Proto je rozdělíme do menších skupin a každá skupina má svoje **directory**, která definuje, jaká data jsou používaná a jaký procesor je využívá.

![image.png](PAP%20210363fcd29e808899b7ede5a6b9f928/image%2020.png)

Existuje centrální místo v paměti, která nám ukládá veškeré informace a zde můžem zjistit, jaký node používá jaká data.

Může být ve stavu jako MOESI.

Může být buďto:

- Flat - každý node má svoji paměť
    - memory - pamatuji si všechno
    - cached - linked list, pamatuji si jenom první
- Hierarchical
- Centralized - jedna společná

# Rules for execution synchronization and data exchange

- [ ]  Rules for execution synchronization and data exchange in multiprocessor systems, mutex implementation, relation to consistency models and mechanism to achieve expected algorithms behavior on systems with relaxed consistency models (PRAM, PSO, TSO, PC, barrier instructions).

**Sekvenční konzistence** - relaxace, relaxuje pouze logické hodiny, tj. že se nemusejí stát ve stejný moment ale ve stejném pořadí.

# SMP and NUMA networks

- [ ]  SMP and NUMA nodes interconnections networks, conflicts and rearrangeable networks Beneš network.

# Parallel computations (OpenMP and MPI)

- [ ]  Parallel computations on multiprocessor systems, OpenMP on NUMA and MPI on distributed memory systems, their combinations.